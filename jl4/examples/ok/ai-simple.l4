-- Simple working example: Query LLMs from L4 using the llm.l4 library
-- This demonstrates LLM querying with automatic provider fallback and response parsing

IMPORT llm

-- Example 1: Simplest possible query with automatic provider fallback
-- This will try OpenRouter -> OpenAI -> Anthropic in order
DECIDE simpleQuery IS
  queryLLMWithDefaults "What is 2+2?"

-- Example 2: Query and parse the response to extract just the text
DECIDE queryAndParse IS
  LET rawResponse BE queryLLMWithDefaults "What is consideration in contract law?"
  IN
    CONSIDER extractLLMResponse "openrouter" rawResponse
      WHEN RIGHT text THEN text
      WHEN LEFT error THEN CONCAT "Error: " error

-- Example 3: Use a specific provider directly
DECIDE anthropicQuery IS
  CONSIDER ENV "ANTHROPIC_API_KEY"
    WHEN JUST key THEN
      LET rawResponse BE callClaude key "Define legal capacity"
      IN
        extractLLMResponse "anthropic" rawResponse
    WHEN NOTHING THEN
      LEFT "ERROR: ANTHROPIC_API_KEY not set"

-- To run these examples, set at least one API key:
-- export OPENROUTER_API_KEY="sk-or-v1-..."
-- export OPENAI_API_KEY="sk-..."
-- export ANTHROPIC_API_KEY="sk-ant-..."
--
-- Then uncomment one of the EVAL lines:
-- #EVAL simpleQuery
-- #EVAL queryAndParse
-- #EVAL anthropicQuery
